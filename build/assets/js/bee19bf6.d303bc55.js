"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_textbook=self.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[939],{8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>a});var i=s(6540);const t={},l=i.createContext(t);function r(e){const n=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(l.Provider,{value:n},e.children)}},9923:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"modules/m4-vla/m4-capstone-project","title":"Lesson 3: Capstone Project - Autonomous Humanoid","description":"Build a complete end-to-end autonomous humanoid system. Voice \u2192 Perception \u2192 Planning \u2192 Execution.","source":"@site/docs/modules/m4-vla/m4-capstone-project.mdx","sourceDirName":"modules/m4-vla","slug":"/modules/m4-vla/m4-capstone-project","permalink":"/docs/modules/m4-vla/m4-capstone-project","draft":false,"unlisted":false,"editUrl":"https://github.com/Danishhshahid/Physical-AI-Humanoid-Robotics-Book/tree/main/website/docs/modules/m4-vla/m4-capstone-project.mdx","tags":[],"version":"current","frontMatter":{"id":"m4-capstone-project","title":"Lesson 3: Capstone Project - Autonomous Humanoid","sidebar_label":"L3: Capstone Project","description":"Build a complete end-to-end autonomous humanoid system. Voice \u2192 Perception \u2192 Planning \u2192 Execution."},"sidebar":"tutorialSidebar","previous":{"title":"L2: Cognitive Planning","permalink":"/docs/modules/m4-vla/m4-cognitive-planning"}}');var t=s(4848),l=s(8453);const r={id:"m4-capstone-project",title:"Lesson 3: Capstone Project - Autonomous Humanoid",sidebar_label:"L3: Capstone Project",description:"Build a complete end-to-end autonomous humanoid system. Voice \u2192 Perception \u2192 Planning \u2192 Execution."},a=void 0,c={},o=[{value:"The Autonomous Humanoid Challenge",id:"the-autonomous-humanoid-challenge",level:2},{value:"Example Tasks:",id:"example-tasks",level:3},{value:"System Architecture",id:"system-architecture",level:2},{value:"Implementation Guide",id:"implementation-guide",level:2},{value:"1. Setup Workspace",id:"1-setup-workspace",level:3},{value:"2. Launch Full System",id:"2-launch-full-system",level:3},{value:"3. Step Executor",id:"3-step-executor",level:3},{value:"4. Testing Checklist",id:"4-testing-checklist",level:3},{value:"Evaluation Criteria",id:"evaluation-criteria",level:2},{value:"Success Metrics:",id:"success-metrics",level:3},{value:"Stretch Goals",id:"stretch-goals",level:2},{value:"Final Submission",id:"final-submission",level:2},{value:"Congratulations!",id:"congratulations",level:2},{value:"What&#39;s Next?",id:"whats-next",level:2},{value:"Module 4 Complete!",id:"module-4-complete",level:2}];function d(e){const n={code:"code",h2:"h2",h3:"h3",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"the-autonomous-humanoid-challenge",children:"The Autonomous Humanoid Challenge"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Mission"}),": Build a humanoid robot that can understand voice commands and execute complex manipulation tasks in a simulated environment."]}),"\n",(0,t.jsx)(n.h3,{id:"example-tasks",children:"Example Tasks:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:'"Organize the shelf"'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Perceive objects on shelf"}),"\n",(0,t.jsx)(n.li,{children:"Identify misaligned items"}),"\n",(0,t.jsx)(n.li,{children:"Rearrange to neat configuration"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:'"Prepare the table for dinner"'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Clear clutter"}),"\n",(0,t.jsx)(n.li,{children:"Place plates and utensils"}),"\n",(0,t.jsx)(n.li,{children:"Set up napkins"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:'"Fetch and carry"'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Find object by description"}),"\n",(0,t.jsx)(n.li,{children:"Navigate there safely"}),"\n",(0,t.jsx)(n.li,{children:"Carry object to destination"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'\r\n                    Voice Input (Microphone)                  \r\n\r\n                            \u2193\r\n\r\n              Whisper: Speech-to-Text (Module 4.1)            \r\n\r\n                            \u2193\r\n\r\n          Llama 3: Task Planning (Module 4.2)                \r\n          Input: "Organize the shelf"                        \r\n          Output: JSON task plan                             \r\n\r\n                            \u2193\r\n\r\n              Step Executor & Coordinator                      \r\n  - Perception: YOLO object detection + CLIP                \r\n  - Localization: VSLAM (Isaac ROS)                         \r\n  - Navigation: Nav2 path planning                          \r\n  - Manipulation: Inverse kinematics + trajectory planning  \r\n  - Safety: Constraint checking                            \r\n\r\n                            \u2193\r\n\r\n              ROS 2 Controllers (Module 1)                    \r\n  - Joint controllers                                       \r\n  - Gripper control                                        \r\n  - Mobile base control                                    \r\n\r\n                            \u2193\r\n\r\n           Gazebo Simulation (Module 2) / Real Robot         \r\n  - Physics simulation                                       \r\n  - Sensor data                                             \r\n  - Actuator feedback                                       \r\n\r\n                            \u2193\r\n                      Task Complete!\n'})}),"\n",(0,t.jsx)(n.h2,{id:"implementation-guide",children:"Implementation Guide"}),"\n",(0,t.jsx)(n.h3,{id:"1-setup-workspace",children:"1. Setup Workspace"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Create workspace\r\nmkdir -p ~/humanoid_ws/src\r\ncd ~/humanoid_ws\r\n\r\n# Clone modules\r\ngit clone https://github.com/YourRepo/humanoid-modules.git\r\n\r\n# Build\r\ncolcon build --symlink-install\r\nsource install/setup.bash\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-launch-full-system",children:"2. Launch Full System"}),"\n",(0,t.jsxs)(n.p,{children:["Create ",(0,t.jsx)(n.code,{children:"complete_system.launch.py"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from launch import LaunchDescription\r\nfrom launch_ros.actions import Node\r\nfrom launch.actions import IncludeLaunchDescription\r\n\r\ndef generate_launch_description():\r\n    # Gazebo simulation\r\n    gazebo = IncludeLaunchDescription(...)\r\n\r\n    # SLAM/Localization\r\n    slam = Node(package='slam_toolbox', executable='async_slam_toolbox_node')\r\n\r\n    # Navigation\r\n    nav2 = IncludeLaunchDescription(...)\r\n\r\n    # Whisper node (speech-to-text)\r\n    whisper = Node(\r\n        package='voice_package',\r\n        executable='whisper_node'\r\n    )\r\n\r\n    # Task planner (LLM)\r\n    planner = Node(\r\n        package='planning_package',\r\n        executable='task_planner'\r\n    )\r\n\r\n    # Step executor\r\n    executor = Node(\r\n        package='execution_package',\r\n        executable='step_executor'\r\n    )\r\n\r\n    # Perception (vision)\r\n    perception = Node(\r\n        package='perception_package',\r\n        executable='perception_node'\r\n    )\r\n\r\n    return LaunchDescription([\r\n        gazebo,\r\n        slam,\r\n        nav2,\r\n        whisper,\r\n        planner,\r\n        executor,\r\n        perception\r\n    ])\n"})}),"\n",(0,t.jsx)(n.p,{children:"Run it:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"ros2 launch humanoid_bringup complete_system.launch.py\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-step-executor",children:"3. Step Executor"}),"\n",(0,t.jsx)(n.p,{children:"Coordinates execution of planned steps:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class StepExecutor(Node):\r\n    def __init__(self):\r\n        super().__init__(\'step_executor\')\r\n        self.plan_sub = self.create_subscription(\r\n            String, \'/robot/plan\', self.plan_callback, 10\r\n        )\r\n        self.step_index = 0\r\n        self.current_plan = None\r\n\r\n    def plan_callback(self, msg):\r\n        """Receive new plan and start execution."""\r\n        self.current_plan = json.loads(msg.data)\r\n        self.step_index = 0\r\n        self.execute_next_step()\r\n\r\n    def execute_next_step(self):\r\n        """Execute current step and move to next."""\r\n        if self.step_index >= len(self.current_plan[\'steps\']):\r\n            self.get_logger().info("Task complete!")\r\n            return\r\n\r\n        step = self.current_plan[\'steps\'][self.step_index]\r\n        self.get_logger().info(f"Executing step {step[\'step_number\']}: {step[\'description\']}")\r\n\r\n        action = step[\'ros_action\']\r\n        params = step[\'parameters\']\r\n\r\n        if action == \'navigate\':\r\n            self.execute_navigate(params)\r\n        elif action == \'perception\':\r\n            self.execute_perception(params)\r\n        elif action == \'move_arm\':\r\n            self.execute_move_arm(params)\r\n        elif action == \'grasp\':\r\n            self.execute_grasp(params)\r\n        elif action == \'release\':\r\n            self.execute_release(params)\r\n\r\n        self.step_index += 1\r\n        self.execute_next_step()\r\n\r\n    def execute_navigate(self, params):\r\n        """Navigate to target location."""\r\n        # Call Nav2 service\r\n        pass\r\n\r\n    def execute_perception(self, params):\r\n        """Perceive environment (detect objects)."""\r\n        # Call object detection service\r\n        pass\r\n\r\n    def execute_move_arm(self, params):\r\n        """Move arm to target."""\r\n        # Compute IK, generate trajectory\r\n        pass\r\n\r\n    def execute_grasp(self, params):\r\n        """Grasp object with force control."""\r\n        # Control gripper with force feedback\r\n        pass\r\n\r\n    def execute_release(self, params):\r\n        """Release object."""\r\n        # Open gripper gradually\r\n        pass\n'})}),"\n",(0,t.jsx)(n.h3,{id:"4-testing-checklist",children:"4. Testing Checklist"}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,t.jsx)(n.strong,{children:"Voice Input"})]}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Whisper correctly transcribes speech in quiet environment"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Handles accent variation"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Recognizes all expected commands"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,t.jsx)(n.strong,{children:"Task Planning"})]}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","LLM generates valid JSON plans"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Plans are feasible (within robot capabilities)"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Safety constraints are respected"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,t.jsx)(n.strong,{children:"Perception"})]}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Object detection works in simulated environment"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Localization drift < 10 cm over 5 minutes"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Depth estimation accurate within 5%"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,t.jsx)(n.strong,{children:"Navigation"})]}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Reaches goal location within 0.5m tolerance"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Avoids simulated obstacles"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Replans when path blocked"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,t.jsx)(n.strong,{children:"Manipulation"})]}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Grasps objects successfully > 90% of time"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Gripper force feedback functional"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Smooth, collision-free trajectories"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,t.jsx)(n.strong,{children:"System Integration"})]}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","All ROS 2 topics communicate correctly"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","No dropped messages under load"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Graceful error recovery"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"evaluation-criteria",children:"Evaluation Criteria"}),"\n",(0,t.jsx)(n.h3,{id:"success-metrics",children:"Success Metrics:"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Autonomous Task Execution"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Level 1"}),': Execute single-step commands ("Pick up the cube")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Level 2"}),': Execute multi-step tasks with planning ("Put the cube on the shelf")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Level 3"}),': Handle ambiguity and ask clarifications ("Should I arrange by color or size?")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Level 4"}),': Recover from failures and replan ("Object not found, searching alternative location...")']}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Robustness"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Task success rate > 80% in simulation"}),"\n",(0,t.jsx)(n.li,{children:"Graceful handling of perception failures"}),"\n",(0,t.jsx)(n.li,{children:"Safe execution (no self-collisions, environment collisions)"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Performance"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"End-to-end latency: Voice command \u2192 Task complete < 5 minutes"}),"\n",(0,t.jsx)(n.li,{children:"Perception latency < 500 ms"}),"\n",(0,t.jsx)(n.li,{children:"Planning latency < 2 seconds"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"stretch-goals",children:"Stretch Goals"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Multi-object manipulation"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'"Organize all red objects on the shelf"'}),"\n",(0,t.jsx)(n.li,{children:"Handle multiple object interactions"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Human-robot collaboration"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Follow human around room"}),"\n",(0,t.jsx)(n.li,{children:"Assist with task"}),"\n",(0,t.jsx)(n.li,{children:"React to human gestures"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Long-horizon planning"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:'"Prepare the kitchen for dinner"'}),"\n",(0,t.jsx)(n.li,{children:"10+ subtasks with dependencies"}),"\n",(0,t.jsx)(n.li,{children:"Handle task interdependencies"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Continual learning"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Learn new object categories from user feedback"}),"\n",(0,t.jsx)(n.li,{children:"Adapt to new environments"}),"\n",(0,t.jsx)(n.li,{children:"Improve over time"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"final-submission",children:"Final Submission"}),"\n",(0,t.jsx)(n.p,{children:"Document your system:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"README.md"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"System architecture diagram"}),"\n",(0,t.jsx)(n.li,{children:"Installation instructions"}),"\n",(0,t.jsx)(n.li,{children:"Usage examples"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Video Demo"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Voice command"}),"\n",(0,t.jsx)(n.li,{children:"Perception"}),"\n",(0,t.jsx)(n.li,{children:"Execution"}),"\n",(0,t.jsx)(n.li,{children:"Success/failure cases"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Performance Report"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Metrics on test tasks"}),"\n",(0,t.jsx)(n.li,{children:"Failure analysis"}),"\n",(0,t.jsx)(n.li,{children:"Future improvements"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Code Documentation"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Well-commented ROS 2 nodes"}),"\n",(0,t.jsx)(n.li,{children:"Launch files"}),"\n",(0,t.jsx)(n.li,{children:"Configuration YAML"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"congratulations",children:"Congratulations!"}),"\n",(0,t.jsxs)(n.p,{children:["You've built a ",(0,t.jsx)(n.strong,{children:"production-grade autonomous humanoid system"})," that demonstrates:"]}),"\n",(0,t.jsx)(n.p,{children:"Natural language understanding (Whisper + Llama 3)\r\nSemantic task planning with LLMs\r\nRobust perception (YOLO + CLIP + VSLAM)\r\nSafe path planning (Nav2)\r\nPrecise manipulation (IK + trajectory planning)\r\nReal-time ROS 2 integration\r\nSim-to-real ready (Gazebo + domain randomization)"}),"\n",(0,t.jsxs)(n.p,{children:["This is the ",(0,t.jsx)(n.strong,{children:"future of robotics"}),": humanoids that understand and execute natural language commands."]}),"\n",(0,t.jsx)(n.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Deploy to real hardware (Tesla Bot, Boston Dynamics Atlas, etc.)"}),"\n",(0,t.jsx)(n.li,{children:"Scale to multi-robot systems"}),"\n",(0,t.jsx)(n.li,{children:"Add continual learning capabilities"}),"\n",(0,t.jsx)(n.li,{children:"Integrate with cloud services for complex reasoning"}),"\n",(0,t.jsx)(n.li,{children:"Build human-robot collaboration systems"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"module-4-complete",children:"Module 4 Complete!"}),"\n",(0,t.jsx)(n.p,{children:"You've completed all 4 modules:"}),"\n",(0,t.jsx)(n.p,{children:"Module 1: The Robotic Nervous System (ROS 2)\r\nModule 2: The Digital Twin (Gazebo & Unity)\r\nModule 3: The AI-Robot Brain (NVIDIA Isaac)\r\nModule 4: Vision-Language-Action (VLA)"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"You are now ready to build autonomous humanoid robots."})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Next Steps"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Deploy to real robots"}),"\n",(0,t.jsx)(n.li,{children:"Contribute to open-source robotics projects"}),"\n",(0,t.jsx)(n.li,{children:"Build your own humanoid startup"}),"\n",(0,t.jsx)(n.li,{children:"Research advanced topics (reinforcement learning, multi-agent systems, etc.)"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Thank you for completing this textbook!"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Created by Danish Abbasi for the GIAIC Community"})})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);