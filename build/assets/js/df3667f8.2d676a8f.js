"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_textbook=self.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[961],{3006:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"modules/m2-digital-twin/m2-sensor-simulation","title":"Lesson 3: Sensor Simulation","description":"Simulate realistic sensors in Gazebo: cameras (RGB/depth), IMU, force/torque sensors. Add noise and calibrate for sim-to-real transfer.","source":"@site/docs/modules/m2-digital-twin/m2-sensor-simulation.mdx","sourceDirName":"modules/m2-digital-twin","slug":"/modules/m2-digital-twin/m2-sensor-simulation","permalink":"/docs/modules/m2-digital-twin/m2-sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Danishhshahid/Physical-AI-Humanoid-Robotics-Book/tree/main/website/docs/modules/m2-digital-twin/m2-sensor-simulation.mdx","tags":[],"version":"current","frontMatter":{"id":"m2-sensor-simulation","title":"Lesson 3: Sensor Simulation","sidebar_label":"L3: Sensor Simulation","description":"Simulate realistic sensors in Gazebo: cameras (RGB/depth), IMU, force/torque sensors. Add noise and calibrate for sim-to-real transfer."},"sidebar":"tutorialSidebar","previous":{"title":"L2: Unity Rendering","permalink":"/docs/modules/m2-digital-twin/m2-unity-rendering"},"next":{"title":"M3: Overview","permalink":"/docs/modules/m3-isaac/m3-overview"}}');var s=r(4848),a=r(8453);const o={id:"m2-sensor-simulation",title:"Lesson 3: Sensor Simulation",sidebar_label:"L3: Sensor Simulation",description:"Simulate realistic sensors in Gazebo: cameras (RGB/depth), IMU, force/torque sensors. Add noise and calibrate for sim-to-real transfer."},t=void 0,l={},c=[{value:"Why Simulate Sensors?",id:"why-simulate-sensors",level:2},{value:"Camera Simulation in Gazebo",id:"camera-simulation-in-gazebo",level:2},{value:"Subscribe to Camera in ROS 2",id:"subscribe-to-camera-in-ros-2",level:3},{value:"IMU Simulation",id:"imu-simulation",level:2},{value:"Read IMU in ROS 2",id:"read-imu-in-ros-2",level:3},{value:"Force/Torque Sensors",id:"forcetorque-sensors",level:2},{value:"Monitor Gripper Force",id:"monitor-gripper-force",level:3},{value:"Depth Camera (LiDAR)",id:"depth-camera-lidar",level:2},{value:"Domain Randomization for Sensors",id:"domain-randomization-for-sensors",level:2},{value:"Hands-On Project",id:"hands-on-project",level:2},{value:"Next Module",id:"next-module",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"why-simulate-sensors",children:"Why Simulate Sensors?"}),"\n",(0,s.jsx)(n.p,{children:"Real sensors have:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Noise and blur"})," (cameras)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Drift"})," (IMU, encoders)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Latency"})," (communication delays)"]}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.strong,{children:"Limited range and accuracy"})}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Training with simulated sensors \u2192 Policies robust to real-world imperfections."}),"\n",(0,s.jsx)(n.h2,{id:"camera-simulation-in-gazebo",children:"Camera Simulation in Gazebo"}),"\n",(0,s.jsx)(n.p,{children:"Add a camera to your URDF:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<link name="camera_link">\r\n  <inertial>\r\n    <mass value="0.1"/>\r\n    <inertia ixx="0.001" ixy="0" ixz="0"\r\n             iyy="0.001" iyz="0" izz="0.001"/>\r\n  </inertial>\r\n  <collision>\r\n    <geometry>\r\n      <box size="0.02 0.02 0.02"/>\r\n    </geometry>\r\n  </collision>\r\n  <visual>\r\n    <geometry>\r\n      <box size="0.02 0.02 0.02"/>\r\n    </geometry>\r\n  </visual>\r\n</link>\r\n\r\n\x3c!-- Mount camera on gripper --\x3e\r\n<joint name="camera_joint" type="fixed">\r\n  <parent link="gripper"/>\r\n  <child link="camera_link"/>\r\n  <origin xyz="0 0 0.05" rpy="0 0 0"/>\r\n</joint>\r\n\r\n\x3c!-- Gazebo plugin for camera sensor --\x3e\r\n<gazebo reference="camera_link">\r\n  <sensor name="camera" type="camera">\r\n    <camera>\r\n      <horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees --\x3e\r\n      <image>\r\n        <width>640</width>\r\n        <height>480</height>\r\n        <format>R8G8B8</format>\r\n      </image>\r\n      <clip>\r\n        <near>0.05</near>\r\n        <far>50.0</far>\r\n      </clip>\r\n      <noise>\r\n        <type>gaussian</type>\r\n        <mean>0.0</mean>\r\n        <stddev>0.007</stddev>\r\n      </noise>\r\n    </camera>\r\n    <plugin filename="ignition-gazebo-camera-video-recorder-system"\r\n            name="ignition::gazebo::systems::VideoRecorder">\r\n      <video_name>camera_output</video_name>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"subscribe-to-camera-in-ros-2",children:"Subscribe to Camera in ROS 2"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nfrom cv_bridge import CvBridge\r\nimport cv2\r\n\r\nclass CameraProcessor(Node):\r\n    def __init__(self):\r\n        super().__init__('camera_processor')\r\n        self.subscription = self.create_subscription(\r\n            Image,\r\n            '/camera/image_raw',\r\n            self.camera_callback,\r\n            10\r\n        )\r\n        self.cv_bridge = CvBridge()\r\n\r\n    def camera_callback(self, msg):\r\n        # Convert ROS Image to OpenCV\r\n        frame = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\r\n\r\n        # Process (e.g., object detection)\r\n        # ...\r\n\r\n        # Publish results\r\n        # ...\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = CameraProcessor()\r\n    rclpy.spin(node)\r\n    node.destroy_node()\r\n    rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,s.jsx)(n.p,{children:"Add accelerometer + gyroscope:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="torso_link">\r\n  <sensor name="imu_sensor" type="imu">\r\n    <always_on>true</always_on>\r\n    <update_rate>200</update_rate>  \x3c!-- 200 Hz --\x3e\r\n    <plugin filename="ignition-gazebo-imu-system" name="ignition::gazebo::systems::Imu">\r\n      \x3c!-- Accelerometer noise --\x3e\r\n      <accel_x_noise mean="0.0" stddev="0.02"/>\r\n      <accel_y_noise mean="0.0" stddev="0.02"/>\r\n      <accel_z_noise mean="0.0" stddev="0.02"/>\r\n\r\n      \x3c!-- Gyroscope noise --\x3e\r\n      <gyro_x_noise mean="0.0" stddev="0.004"/>\r\n      <gyro_y_noise mean="0.0" stddev="0.004"/>\r\n      <gyro_z_noise mean="0.0" stddev="0.004"/>\r\n\r\n      \x3c!-- Bias (drift) --\x3e\r\n      <accel_bias_x_noise mean="0.001" stddev="0.0001"/>\r\n      <accel_bias_y_noise mean="0.001" stddev="0.0001"/>\r\n      <accel_bias_z_noise mean="0.001" stddev="0.0001"/>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"read-imu-in-ros-2",children:"Read IMU in ROS 2"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from sensor_msgs.msg import Imu\r\nimport numpy as np\r\n\r\nclass BalanceController(Node):\r\n    def __init__(self):\r\n        super().__init__('balance_controller')\r\n        self.imu_sub = self.create_subscription(\r\n            Imu,\r\n            '/imu/data',\r\n            self.imu_callback,\r\n            10\r\n        )\r\n        self.accel = np.zeros(3)\r\n        self.angular_vel = np.zeros(3)\r\n\r\n    def imu_callback(self, msg):\r\n        # Extract linear acceleration\r\n        self.accel = np.array([\r\n            msg.linear_acceleration.x,\r\n            msg.linear_acceleration.y,\r\n            msg.linear_acceleration.z\r\n        ])\r\n\r\n        # Extract angular velocity\r\n        self.angular_vel = np.array([\r\n            msg.angular_velocity.x,\r\n            msg.angular_velocity.y,\r\n            msg.angular_velocity.z\r\n        ])\r\n\r\n        # Use for balance control\r\n        # Example: Estimate center-of-mass acceleration\r\n        com_accel_z = self.accel[2]  # Vertical acceleration\r\n\r\n        if com_accel_z < 0:  # Falling forward\r\n            self.adjust_hip_angle(delta=0.01)  # Lean back\n"})}),"\n",(0,s.jsx)(n.h2,{id:"forcetorque-sensors",children:"Force/Torque Sensors"}),"\n",(0,s.jsx)(n.p,{children:"Simulate gripper force feedback:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="gripper_link">\r\n  <sensor name="force_torque" type="force_torque">\r\n    <always_on>true</always_on>\r\n    <update_rate>100</update_rate>\r\n    <plugin filename="ignition-gazebo-force-torque-system"\r\n            name="ignition::gazebo::systems::ForceTorque">\r\n      <force_x_noise mean="0.0" stddev="0.1"/>\r\n      <force_y_noise mean="0.0" stddev="0.1"/>\r\n      <force_z_noise mean="0.0" stddev="0.1"/>\r\n      <torque_x_noise mean="0.0" stddev="0.01"/>\r\n      <torque_y_noise mean="0.0" stddev="0.01"/>\r\n      <torque_z_noise mean="0.0" stddev="0.01"/>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"monitor-gripper-force",children:"Monitor Gripper Force"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from geometry_msgs.msg import WrenchStamped\r\n\r\nclass GripperController(Node):\r\n    def __init__(self):\r\n        super().__init__('gripper_controller')\r\n        self.ft_sub = self.create_subscription(\r\n            WrenchStamped,\r\n            '/gripper/force_torque',\r\n            self.ft_callback,\r\n            10\r\n        )\r\n\r\n    def ft_callback(self, msg):\r\n        force_z = msg.wrench.force.z  # Vertical grip force\r\n\r\n        if force_z > 50:  # Too much force\r\n            self.reduce_gripper_current()\r\n        elif force_z < 10:  # Object slipping\r\n            self.increase_gripper_current()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"depth-camera-lidar",children:"Depth Camera (LiDAR)"}),"\n",(0,s.jsx)(n.p,{children:"Simulate 3D depth sensing:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="head_link">\r\n  <sensor name="depth_camera" type="depth_camera">\r\n    <always_on>true</always_on>\r\n    <update_rate>30</update_rate>\r\n    <camera>\r\n      <horizontal_fov>1.047</horizontal_fov>\r\n      <image>\r\n        <width>640</width>\r\n        <height>480</height>\r\n      </image>\r\n      <clip>\r\n        <near>0.1</near>\r\n        <far>5.0</far>\r\n      </clip>\r\n    </camera>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,s.jsx)(n.p,{children:"Process depth data for obstacle avoidance:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from sensor_msgs.msg import Image\r\nimport numpy as np\r\n\r\nclass ObstacleDetector(Node):\r\n    def depth_callback(self, msg):\r\n        # Convert to numpy array\r\n        depth_array = np.frombuffer(msg.data, dtype=np.uint16)\r\n        depth_image = depth_array.reshape((msg.height, msg.width))\r\n\r\n        # Find closest obstacle\r\n        min_distance = np.min(depth_image[depth_image > 0])\r\n\r\n        if min_distance < 0.3:  # 30 cm warning\r\n            self.get_logger().warn("Obstacle detected!")\r\n            self.emergency_stop()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"domain-randomization-for-sensors",children:"Domain Randomization for Sensors"}),"\n",(0,s.jsx)(n.p,{children:"Train policies robust to sensor uncertainty:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import random\r\nimport subprocess\r\n\r\ndef randomize_simulation():\r\n    \"\"\"Randomize sensor parameters before each training episode.\"\"\"\r\n\r\n    # Randomize camera noise\r\n    camera_noise = random.uniform(0.001, 0.02)\r\n\r\n    # Randomize IMU drift\r\n    imu_drift = random.uniform(0.0001, 0.001)\r\n\r\n    # Randomize force sensor noise\r\n    ft_noise = random.uniform(0.01, 0.5)\r\n\r\n    # Rewrite URDF/SDF with new parameters\r\n    # ...\r\n\r\n    # Restart Gazebo simulation\r\n    subprocess.run(['pkill', 'gazebo'])\r\n    subprocess.run(['gazebo', 'randomized_world.sdf'])\n"})}),"\n",(0,s.jsx)(n.h2,{id:"hands-on-project",children:"Hands-On Project"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Simulate a manipulation task with complete sensor suite:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Create a scene with:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A table with 3 objects"}),"\n",(0,s.jsx)(n.li,{children:"A humanoid arm with 6-DOF"}),"\n",(0,s.jsx)(n.li,{children:"RGB camera on gripper"}),"\n",(0,s.jsx)(n.li,{children:"Depth sensor on head"}),"\n",(0,s.jsx)(n.li,{children:"IMU on torso"}),"\n",(0,s.jsx)(n.li,{children:"F/T sensor on wrist"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Implement controllers:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Vision-based object detection"}),"\n",(0,s.jsx)(n.li,{children:"Balance control using IMU"}),"\n",(0,s.jsx)(n.li,{children:"Grasp force control using F/T sensor"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Train a policy that:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Sees an object with the camera"}),"\n",(0,s.jsx)(n.li,{children:"Plans a grasp trajectory"}),"\n",(0,s.jsx)(n.li,{children:"Executes with force feedback"}),"\n",(0,s.jsx)(n.li,{children:"Verifies success with depth sensor"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"next-module",children:"Next Module"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"/docs/modules/m3-isaac/m3-overview",children:"Module 3: The AI-Robot Brain (NVIDIA Isaac)"})})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>t});var i=r(6540);const s={},a=i.createContext(s);function o(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);