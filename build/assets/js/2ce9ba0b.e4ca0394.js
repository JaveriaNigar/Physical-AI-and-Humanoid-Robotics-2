"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_textbook=self.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[521],{2775:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"modules/m2-digital-twin/m2-unity-rendering","title":"Lesson 2: Unity Rendering & Visualization","description":"Build photorealistic robot visualizations in Unity. Stream sensor data from Gazebo and create interactive dashboards for humanoid control.","source":"@site/docs/modules/m2-digital-twin/m2-unity-rendering.mdx","sourceDirName":"modules/m2-digital-twin","slug":"/modules/m2-digital-twin/m2-unity-rendering","permalink":"/docs/modules/m2-digital-twin/m2-unity-rendering","draft":false,"unlisted":false,"editUrl":"https://github.com/Danishhshahid/Physical-AI-Humanoid-Robotics-Book/tree/main/website/docs/modules/m2-digital-twin/m2-unity-rendering.mdx","tags":[],"version":"current","frontMatter":{"id":"m2-unity-rendering","title":"Lesson 2: Unity Rendering & Visualization","sidebar_label":"L2: Unity Rendering","description":"Build photorealistic robot visualizations in Unity. Stream sensor data from Gazebo and create interactive dashboards for humanoid control."},"sidebar":"tutorialSidebar","previous":{"title":"L1: Gazebo Physics","permalink":"/docs/modules/m2-digital-twin/m2-gazebo-physics"},"next":{"title":"L3: Sensor Simulation","permalink":"/docs/modules/m2-digital-twin/m2-sensor-simulation"}}');var t=i(4848),o=i(8453);const a={id:"m2-unity-rendering",title:"Lesson 2: Unity Rendering & Visualization",sidebar_label:"L2: Unity Rendering",description:"Build photorealistic robot visualizations in Unity. Stream sensor data from Gazebo and create interactive dashboards for humanoid control."},s=void 0,l={},d=[{value:"Why Unity for Visualization?",id:"why-unity-for-visualization",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Setting Up Unity with ROS 2",id:"setting-up-unity-with-ros-2",level:2},{value:"Install ROS 2 for Unity",id:"install-ros-2-for-unity",level:3},{value:"Export Robot Model to FBX",id:"export-robot-model-to-fbx",level:3},{value:"Real-Time Camera Streaming",id:"real-time-camera-streaming",level:2},{value:"Visualizing Trajectories",id:"visualizing-trajectories",level:2},{value:"Interactive Teleoperation",id:"interactive-teleoperation",level:2},{value:"Lighting &amp; Materials",id:"lighting--materials",level:2},{value:"Hands-On Project",id:"hands-on-project",level:2},{value:"Next Lesson",id:"next-lesson",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"why-unity-for-visualization",children:"Why Unity for Visualization?"}),"\n",(0,t.jsxs)(n.p,{children:["Gazebo provides physics but limited visual fidelity. ",(0,t.jsx)(n.strong,{children:"Unity"})," excels at:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Photorealistic rendering"}),": High-quality graphics, realistic materials"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real-time interaction"}),": Teleoperation dashboards"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data visualization"}),": Live sensor streams, planning visualization"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Human-robot interaction"}),": Show robot capabilities to stakeholders"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Modern robots stream their state from ROS 2 to Unity for rich visualization."}),"\n",(0,t.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Gazebo (Physics) \u2194 ROS 2 \u2194 Unity (Rendering)\r\n Robot state (poses)\r\n Sensor data (camera feeds, IMU)\r\n Planned trajectories\n"})}),"\n",(0,t.jsx)(n.h2,{id:"setting-up-unity-with-ros-2",children:"Setting Up Unity with ROS 2"}),"\n",(0,t.jsx)(n.h3,{id:"install-ros-2-for-unity",children:"Install ROS 2 for Unity"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Install ROS-TCP-Connector (bridges ROS 2 to Unity)\r\ngit clone https://github.com/RoboticsToolkit/ros2-for-unity.git\n"})}),"\n",(0,t.jsx)(n.h3,{id:"export-robot-model-to-fbx",children:"Export Robot Model to FBX"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Export from CAD \u2192 URDF \u2192 FBX format"}),"\n",(0,t.jsx)(n.li,{children:"Import FBX into Unity"}),"\n",(0,t.jsx)(n.li,{children:"Attach ROS 2 bridge scripts"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"real-time-camera-streaming",children:"Real-Time Camera Streaming"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing ROS2;\r\n\r\npublic class CameraStreamer : MonoBehaviour {\r\n    private ROS2Node ros2Node;\r\n    private ISubscription<ROS2.Sensor.Image> cameraSubscription;\r\n    private Texture2D cameraTexture;\r\n\r\n    void Start() {\r\n        ros2Node = GetComponent<ROS2Node>();\r\n\r\n        // Subscribe to camera feed\r\n        cameraSubscription = ros2Node.CreateSubscription<ROS2.Sensor.Image>(\r\n            "/camera/image",\r\n            OnCameraFrame\r\n        );\r\n\r\n        cameraTexture = new Texture2D(640, 480, TextureFormat.RGB24, false);\r\n    }\r\n\r\n    void OnCameraFrame(ROS2.Sensor.Image msg) {\r\n        // Convert ROS Image to Unity Texture\r\n        cameraTexture.LoadRawTextureData(msg.data);\r\n        cameraTexture.Apply();\r\n\r\n        // Display on canvas\r\n        GetComponent<RawImage>().texture = cameraTexture;\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"visualizing-trajectories",children:"Visualizing Trajectories"}),"\n",(0,t.jsx)(n.p,{children:"Show planned robot trajectories in real-time:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"using UnityEngine;\r\nusing ROS2.TrajectoryMsgs;\r\n\r\npublic class TrajectoryVisualizer : MonoBehaviour {\r\n    public Material trajMaterial;\r\n    private LineRenderer lineRenderer;\r\n\r\n    void OnTrajectoryReceived(JointTrajectory trajectory) {\r\n        lineRenderer.positionCount = trajectory.points.Count;\r\n\r\n        for (int i = 0; i < trajectory.points.Count; i++) {\r\n            // Convert joint angles to Cartesian position\r\n            Vector3 position = ComputeForwardKinematics(trajectory.points[i].positions);\r\n            lineRenderer.SetPosition(i, position);\r\n        }\r\n    }\r\n\r\n    Vector3 ComputeForwardKinematics(double[] jointAngles) {\r\n        // Implement FK or call ROS 2 service\r\n        // ...\r\n        return Vector3.zero;\r\n    }\r\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"interactive-teleoperation",children:"Interactive Teleoperation"}),"\n",(0,t.jsx)(n.p,{children:"Create a UI for manual robot control:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using UnityEngine;\r\n\r\npublic class TeleoperationPanel : MonoBehaviour {\r\n    private ROS2Node ros2Node;\r\n\r\n    void Update() {\r\n        // Read slider values (0-1 range for each joint)\r\n        float shoulderAngle = GetSliderValue("shoulder");\r\n        float elbowAngle = GetSliderValue("elbow");\r\n\r\n        if (Input.GetButtonDown("Submit")) {\r\n            SendJointCommand(new[] { shoulderAngle, elbowAngle });\r\n        }\r\n    }\r\n\r\n    void SendJointCommand(float[] angles) {\r\n        // Convert to ROS message and publish\r\n        var cmd = new JointTrajectory() {\r\n            JointNames = new[] { "shoulder", "elbow" },\r\n            // ...\r\n        };\r\n\r\n        ros2Node.Publish("/arm/commands", cmd);\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"lighting--materials",children:"Lighting & Materials"}),"\n",(0,t.jsx)(n.p,{children:"Use physically-based materials for realism:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'Material metal = new Material(Shader.Find("Standard"));\r\nmetal.SetFloat("_Metallic", 1.0f);\r\nmetal.SetFloat("_Glossiness", 0.8f);\r\n\r\nMaterial rubber = new Material(Shader.Find("Standard"));\r\nrubber.SetFloat("_Metallic", 0.0f);\r\nrubber.SetFloat("_Glossiness", 0.2f);\n'})}),"\n",(0,t.jsx)(n.h2,{id:"hands-on-project",children:"Hands-On Project"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Export your humanoid arm model to FBX"}),"\n",(0,t.jsx)(n.li,{children:"Import into Unity"}),"\n",(0,t.jsxs)(n.li,{children:["Create a dashboard showing:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Live camera feed"}),"\n",(0,t.jsx)(n.li,{children:"Current joint angles"}),"\n",(0,t.jsx)(n.li,{children:"Planned trajectory visualization"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"Add interactive sliders to control joint angles in real-time"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-lesson",children:"Next Lesson"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"/docs/modules/m2-digital-twin/m2-sensor-simulation",children:"Lesson 3: Sensor Simulation"})})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>s});var r=i(6540);const t={},o=r.createContext(t);function a(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);