"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_textbook=self.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[849],{6164:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Front Matter","items":[{"type":"link","href":"/docs/chapters/ch0-preface","label":"Preface","docId":"chapters/ch0-preface","unlisted":false},{"type":"link","href":"/docs/chapters/ch0-prerequisites","label":"Prerequisites","docId":"chapters/ch0-prerequisites","unlisted":false},{"type":"link","href":"/docs/chapters/ch1-intro","label":"Ch1: Intro to Physical AI","docId":"chapters/ch1-intro","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"link","href":"/docs/modules/m1-ros2/m1-overview","label":"M1: Overview","docId":"modules/m1-ros2/m1-overview","unlisted":false},{"type":"link","href":"/docs/modules/m1-ros2/m1-nodes-topics-services","label":"L1: Nodes, Topics, Services","docId":"modules/m1-ros2/m1-nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/modules/m1-ros2/m1-python-agents","label":"L2: Python Agents to ROS","docId":"modules/m1-ros2/m1-python-agents","unlisted":false},{"type":"link","href":"/docs/modules/m1-ros2/m1-urdf-humanoids","label":"L3: URDF Humanoids","docId":"modules/m1-ros2/m1-urdf-humanoids","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/docs/modules/m2-digital-twin/m2-overview","label":"M2: Overview","docId":"modules/m2-digital-twin/m2-overview","unlisted":false},{"type":"link","href":"/docs/modules/m2-digital-twin/m2-gazebo-physics","label":"L1: Gazebo Physics","docId":"modules/m2-digital-twin/m2-gazebo-physics","unlisted":false},{"type":"link","href":"/docs/modules/m2-digital-twin/m2-unity-rendering","label":"L2: Unity Rendering","docId":"modules/m2-digital-twin/m2-unity-rendering","unlisted":false},{"type":"link","href":"/docs/modules/m2-digital-twin/m2-sensor-simulation","label":"L3: Sensor Simulation","docId":"modules/m2-digital-twin/m2-sensor-simulation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"link","href":"/docs/modules/m3-isaac/m3-overview","label":"M3: Overview","docId":"modules/m3-isaac/m3-overview","unlisted":false},{"type":"link","href":"/docs/modules/m3-isaac/m3-isaac-sim","label":"L1: Isaac Sim","docId":"modules/m3-isaac/m3-isaac-sim","unlisted":false},{"type":"link","href":"/docs/modules/m3-isaac/m3-isaac-ros","label":"L2: Isaac ROS","docId":"modules/m3-isaac/m3-isaac-ros","unlisted":false},{"type":"link","href":"/docs/modules/m3-isaac/m3-nav2-planning","label":"L3: Nav2 Planning","docId":"modules/m3-isaac/m3-nav2-planning","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/docs/modules/m4-vla/m4-overview","label":"M4: Overview","docId":"modules/m4-vla/m4-overview","unlisted":false},{"type":"link","href":"/docs/modules/m4-vla/m4-voice-to-action","label":"L1: Voice-to-Action","docId":"modules/m4-vla/m4-voice-to-action","unlisted":false},{"type":"link","href":"/docs/modules/m4-vla/m4-cognitive-planning","label":"L2: Cognitive Planning","docId":"modules/m4-vla/m4-cognitive-planning","unlisted":false},{"type":"link","href":"/docs/modules/m4-vla/m4-capstone-project","label":"L3: Capstone Project","docId":"modules/m4-vla/m4-capstone-project","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"AUTHENTICATION_GUIDE":{"id":"AUTHENTICATION_GUIDE","title":"Authentication & Personalization Implementation Guide","description":"Overview"},"chapters/ch0-preface":{"id":"chapters/ch0-preface","title":"Preface","description":"Welcome to Physical AI & Humanoid Robotics Essentials. This textbook teaches you how to build AI-powered humanoid robots from first principles.","sidebar":"tutorialSidebar"},"chapters/ch0-prerequisites":{"id":"chapters/ch0-prerequisites","title":"Prerequisites & Notation","description":"Mathematical notation, assumed knowledge, and quick refresher on linear algebra and physics concepts used throughout the textbook.","sidebar":"tutorialSidebar"},"chapters/ch1-intro":{"id":"chapters/ch1-intro","title":"Chapter 1: Introduction to Physical AI","description":"Define Physical AI as embodied AI through perception-action loops. Explore why humanoid robots matter and the convergence of AI + embodied systems in 2025.","sidebar":"tutorialSidebar"},"chapters/ch2-humanoid":{"id":"chapters/ch2-humanoid","title":"Chapter 2: Basics of Humanoid Robotics","description":"Kinematics, dynamics, actuators, and sensing\u2014the engineering fundamentals of humanoid robots. Practical calculations for reaching, grasping, and movement."},"chapters/ch3-ros2":{"id":"chapters/ch3-ros2","title":"Chapter 3: ROS 2 Fundamentals","description":"Nodes, topics, services, packages\u2014building modular robot software with ROS 2 Humble. Practical workflows for real robot systems."},"chapters/ch4-sim":{"id":"chapters/ch4-sim","title":"Chapter 4: Digital Twin Simulation with Gazebo","description":"Master physics simulation, sensor modeling, and sim-to-real transfer for humanoid robotics using Gazebo and URDF."},"chapters/ch5-vla":{"id":"chapters/ch5-vla","title":"Chapter 5: Vision-Language-Action Systems","description":"Integrate large language models (Llama 3) with vision encoders to ground abstract language commands into safe, executable robot trajectories."},"chapters/ch6-capstone":{"id":"chapters/ch6-capstone","title":"Chapter 6: Capstone \u2013 AI-Robot Pipeline in Production","description":"Integrate all components (kinematics, ROS 2, simulation, vision-language models) into a production-ready AI-robot system with Docker, monitoring, and real-world validation."},"modules/m1-ros2/m1-nodes-topics-services":{"id":"modules/m1-ros2/m1-nodes-topics-services","title":"Lesson 1: ROS 2 Nodes, Topics, and Services","description":"Master the core building blocks of ROS 2: nodes (independent processes), topics (pub-sub communication), and services (request-response).","sidebar":"tutorialSidebar"},"modules/m1-ros2/m1-overview":{"id":"modules/m1-ros2/m1-overview","title":"Module 1 Overview: The Robotic Nervous System (ROS 2)","description":"Understand ROS 2 as the middleware that connects all components of a humanoid robot. This module covers nodes, topics, services, and how to bridge Python agents to robotic hardware.","sidebar":"tutorialSidebar"},"modules/m1-ros2/m1-python-agents":{"id":"modules/m1-ros2/m1-python-agents","title":"Lesson 2: Bridging Python Agents to ROS Controllers","description":"Learn how to bridge AI agents (LLMs, planning algorithms) running in Python to actual ROS 2 robot controllers. From voice commands to executed trajectories.","sidebar":"tutorialSidebar"},"modules/m1-ros2/m1-urdf-humanoids":{"id":"modules/m1-ros2/m1-urdf-humanoids","title":"Lesson 3: URDF for Humanoids","description":"Master URDF (Unified Robot Description Format) - the XML language for defining robot structures. Learn to model humanoid kinematic chains, joint limits, and physical properties.","sidebar":"tutorialSidebar"},"modules/m2-digital-twin/m2-gazebo-physics":{"id":"modules/m2-digital-twin/m2-gazebo-physics","title":"Lesson 1: Gazebo Physics Simulation","description":"Master Gazebo for physics-accurate robot simulation. Configure physics engines, set up worlds, and simulate complex interactions.","sidebar":"tutorialSidebar"},"modules/m2-digital-twin/m2-overview":{"id":"modules/m2-digital-twin/m2-overview","title":"Module 2 Overview: The Digital Twin (Gazebo & Unity)","description":"Master physics simulation with Gazebo and high-fidelity visualization with Unity. Simulate complex environments, sensor dynamics, and human-robot interaction.","sidebar":"tutorialSidebar"},"modules/m2-digital-twin/m2-sensor-simulation":{"id":"modules/m2-digital-twin/m2-sensor-simulation","title":"Lesson 3: Sensor Simulation","description":"Simulate realistic sensors in Gazebo: cameras (RGB/depth), IMU, force/torque sensors. Add noise and calibrate for sim-to-real transfer.","sidebar":"tutorialSidebar"},"modules/m2-digital-twin/m2-unity-rendering":{"id":"modules/m2-digital-twin/m2-unity-rendering","title":"Lesson 2: Unity Rendering & Visualization","description":"Build photorealistic robot visualizations in Unity. Stream sensor data from Gazebo and create interactive dashboards for humanoid control.","sidebar":"tutorialSidebar"},"modules/m3-isaac/m3-isaac-ros":{"id":"modules/m3-isaac/m3-isaac-ros","title":"Lesson 2: Isaac ROS (GPU-Accelerated Perception)","description":"Implement hardware-accelerated perception with Isaac ROS: VSLAM, object detection, depth estimation.","sidebar":"tutorialSidebar"},"modules/m3-isaac/m3-isaac-sim":{"id":"modules/m3-isaac/m3-isaac-sim","title":"Lesson 1: NVIDIA Isaac Sim","description":"Master photorealistic robot simulation with NVIDIA Isaac Sim. Generate synthetic training data at scale.","sidebar":"tutorialSidebar"},"modules/m3-isaac/m3-nav2-planning":{"id":"modules/m3-isaac/m3-nav2-planning","title":"Lesson 3: Nav2 Path Planning for Humanoids","description":"Implement autonomous navigation for bipedal humanoid robots using Nav2. Global planning, local planning, and obstacle avoidance.","sidebar":"tutorialSidebar"},"modules/m3-isaac/m3-overview":{"id":"modules/m3-isaac/m3-overview","title":"Module 3 Overview: The AI-Robot Brain (NVIDIA Isaac)","description":"Master NVIDIA Isaac Sim for photorealistic simulation and Isaac ROS for hardware-accelerated perception. Build autonomous humanoid systems with Nav2 path planning.","sidebar":"tutorialSidebar"},"modules/m4-vla/m4-capstone-project":{"id":"modules/m4-vla/m4-capstone-project","title":"Lesson 3: Capstone Project - Autonomous Humanoid","description":"Build a complete end-to-end autonomous humanoid system. Voice \u2192 Perception \u2192 Planning \u2192 Execution.","sidebar":"tutorialSidebar"},"modules/m4-vla/m4-cognitive-planning":{"id":"modules/m4-vla/m4-cognitive-planning","title":"Lesson 2: Cognitive Planning with LLMs","description":"Use large language models to translate natural language into step-by-step robot plans. Handle ambiguity, ask clarifications, ensure safety.","sidebar":"tutorialSidebar"},"modules/m4-vla/m4-overview":{"id":"modules/m4-vla/m4-overview","title":"Module 4 Overview: Vision-Language-Action (VLA)","description":"Master the convergence of large language models and robotics. Build systems where robots understand natural language commands and execute complex tasks.","sidebar":"tutorialSidebar"},"modules/m4-vla/m4-voice-to-action":{"id":"modules/m4-vla/m4-voice-to-action","title":"Lesson 1: Voice-to-Action with Whisper","description":"Build real-time speech recognition for robots using OpenAI Whisper. Convert voice commands into actionable ROS 2 messages.","sidebar":"tutorialSidebar"}}}}')}}]);