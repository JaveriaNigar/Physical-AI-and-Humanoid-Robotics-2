---
id: m1-nodes-topics-services
title: "Lesson 1: ROS 2 Nodes, Topics, and Services"
sidebar_label: "L1: Nodes, Topics, Services"
description: "Master the core building blocks of ROS 2: nodes (independent processes), topics (pub-sub communication), and services (request-response)."
---

## The Three Pillars of ROS 2

ROS 2 is built on three fundamental concepts:

### 1. **Nodes** (Independent Processes)

A **node** is a single executable ROS 2 program. Each node does one specific job:

- **Sensor driver node**: Reads camera frames, publishes them
- **Motor control node**: Listens for joint commands, sends signals to motors
- **Path planner node**: Computes collision-free trajectories
- **AI agent node**: Runs an LLM to generate action sequences

Nodes run independently and communicate via topics or services.

**Key advantage**: If one node crashes, others keep running.

### 2. **Topics** (Publish-Subscribe)

**Topics** are named buses for streaming data. Multiple nodes can:
- **Publish** (send) data to a topic
- **Subscribe** (listen) to a topic

**Example**:
```
 Camera Node → publishes to → /camera/image_raw

 Vision Node → subscribes to /camera/image_raw → processes frames

 Control Node → subscribes to /camera/detections → moves arm to object
```

**Analogy**: Topics are like radio stations. Multiple listeners can tune in to the same broadcast.

### 3. **Services** (Request-Response)

**Services** are like function calls over the network. A client sends a request and waits for a response.

**Example**:
```
 Plan a path
Client: "Move to position (1.0, 0.5, 0.2)"
Server: "OK, computed 50-step trajectory"
```

**Topic vs Service**:

| Aspect | Topic | Service |
|--------|-------|---------|
| **Communication** | One-way stream | Request-Response |
| **Use case** | Continuous data (camera, IMU) | One-time requests (compute, query) |
| **Latency** | Can be high | Low, synchronous |
| **Example** | `/camera/image` | `/move_arm` |

## Writing Your First ROS 2 Node

### Install ROS 2 (Ubuntu 22.04)

```bash
sudo apt install ros-humble-desktop
source /opt/ros/humble/setup.bash
```

### Create a Publisher Node

```python
#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2

class CameraPublisher(Node):
    def __init__(self):
        super().__init__('camera_publisher')

        # Create a publisher for camera frames
        self.publisher = self.create_publisher(Image, '/camera/image', 10)

        # Create a timer to publish every 0.033 seconds (30 Hz)
        timer_period = 0.033
        self.timer = self.create_timer(timer_period, self.timer_callback)

        self.cv_bridge = CvBridge()
        self.cap = cv2.VideoCapture(0)  # Open webcam

        self.get_logger().info("Camera publisher started")

    def timer_callback(self):
        ret, frame = self.cap.read()
        if ret:
            # Convert OpenCV frame to ROS Image message
            img_msg = self.cv_bridge.cv2_to_imgmsg(frame, encoding='bgr8')
            self.publisher.publish(img_msg)
            self.get_logger().debug(f"Published frame {self.publisher.get_subscription_count()} subscribers")

def main(args=None):
    rclpy.init(args=args)
    node = CameraPublisher()
    rclpy.spin(node)  # Keep node running
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

### Create a Subscriber Node

```python
#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2

class CameraSubscriber(Node):
    def __init__(self):
        super().__init__('camera_subscriber')

        # Create a subscriber for camera frames
        self.subscription = self.create_subscription(
            Image,
            '/camera/image',
            self.listener_callback,
            10  # Queue size
        )

        self.cv_bridge = CvBridge()
        self.get_logger().info("Camera subscriber started, waiting for images...")

    def listener_callback(self, msg: Image):
        # Convert ROS Image message to OpenCV frame
        frame = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')

        # Process the frame (e.g., display it)
        cv2.imshow('Camera Feed', frame)
        cv2.waitKey(1)

        self.get_logger().debug(f"Received frame: {msg.header.frame_id}")

def main(args=None):
    rclpy.init(args=args)
    node = CameraSubscriber()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

### Run Publisher and Subscriber

```bash
# Terminal 1: Run publisher
ros2 run my_package camera_publisher

# Terminal 2: Run subscriber
ros2 run my_package camera_subscriber

# Terminal 3: Monitor topics
ros2 topic list          # List all topics
ros2 topic echo /camera/image  # View messages
ros2 topic hz /camera/image    # Check publish rate
```

## Creating a Service

### Service Definition (.srv file)

```
# request
float64 x
float64 y
float64 z
---
# response
geometry_msgs/Pose target_pose
trajectory_msgs/JointTrajectory planned_trajectory
```

### Service Server

```python
from example_interfaces.srv import AddTwoInts

def plan_path_callback(request, response):
    # request has x, y, z
    response.target_pose = ...  # Compute IK
    response.planned_trajectory = ...  # Compute trajectory
    return response

node.create_service(PlanPath, '/plan_path', plan_path_callback)
```

### Service Client

```python
client = node.create_client(PlanPath, '/plan_path')

request = PlanPath.Request()
request.x, request.y, request.z = 1.0, 0.5, 0.2

future = client.call_async(request)
response = future.result()  # Wait for response

print(f"Planned {len(response.planned_trajectory.points)} steps")
```

## Best Practices

1. **One node = one responsibility**
   -  Separate camera driver, vision, and control
   -  Don't put everything in one node

2. **Use meaningful topic names**
   -  `/arm/joint_commands`, `/camera/depth_image`
   -  `/data`, `/messages`

3. **Set appropriate queue sizes**
   - High-frequency sensors: queue_size=10
   - Low-frequency requests: queue_size=1

4. **Log appropriately**
   - `DEBUG`: Detailed per-frame info
   - `INFO`: Important lifecycle events
   - `ERROR`: Failures that require attention

5. **Handle node shutdown gracefully**
   - Always call `destroy_node()` and `shutdown()`

## Next Steps

- [Lesson 2: Bridging Python Agents to ROS Controllers](/docs/modules/m1-ros2/m1-python-agents)
- Hands-on: Create a robot arm controller node that subscribes to `/arm/target_position` and publishes joint angles
- Challenge: Build a node that bridges ChatGPT API to ROS 2 commands
